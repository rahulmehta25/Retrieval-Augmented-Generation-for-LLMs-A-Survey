# Production RAG Configuration

# System Settings
system:
  environment: production
  debug: false
  max_workers: 4
  timeout: 30
  cache_enabled: true
  cache_ttl: 3600

# Chunking Configuration
chunking:
  strategy: semantic  # semantic, fixed, sliding
  chunk_size: 512
  chunk_overlap: 128
  min_chunk_size: 100
  max_chunk_size: 1000
  respect_sentences: true
  respect_paragraphs: true

# Embedding Configuration  
embedding:
  provider: sentence_transformer  # sentence_transformer, openai, cohere
  model: all-MiniLM-L6-v2
  dimension: 384
  batch_size: 32
  normalize: true
  cache_embeddings: true

# Vector Store Configuration
vector_store:
  type: hybrid  # chroma, faiss, hybrid
  persist_directory: ./vector_store_prod
  collection_name: rag_production
  distance_metric: cosine
  index_type: HNSW
  ef_construction: 200
  ef_search: 50
  
# Retrieval Configuration
retrieval:
  strategy: hybrid  # dense, sparse, hybrid
  k_documents: 10
  rerank: true
  reranker_model: cross-encoder/ms-marco-MiniLM-L-6-v2
  rerank_top_k: 5
  use_mmr: true  # Maximal Marginal Relevance
  mmr_lambda: 0.5
  hybrid_alpha: 0.5  # Balance between dense and sparse

# Query Optimization
query_optimization:
  enable: true
  rewrite: true
  expand: true
  decompose: true
  use_hyde: true
  max_expansion: 3
  complexity_threshold: 0.5

# Generation Configuration
generation:
  provider: ollama  # ollama, openai, anthropic, huggingface
  model: gemma:2b
  temperature: 0.7
  max_tokens: 512
  top_p: 0.9
  frequency_penalty: 0.0
  presence_penalty: 0.0
  stop_sequences: ["\n\n", "Human:", "Assistant:"]
  
# Context Configuration
context:
  max_context_length: 2048
  compression_enabled: true
  compression_ratio: 0.5
  summarization_enabled: false
  context_ordering: relevance  # relevance, diversity, recency

# Evaluation Configuration
evaluation:
  enable_ragas: true
  ragas_metrics:
    - faithfulness
    - answer_relevancy
    - context_relevancy
    - context_precision
  min_score_threshold: 0.6
  log_evaluations: true

# Conversation Management
conversation:
  enable_memory: true
  memory_type: buffer  # buffer, summary, knowledge_graph
  max_history: 10
  summarize_after: 5
  context_window: 3

# Monitoring Configuration
monitoring:
  enable_metrics: true
  enable_tracing: true
  log_level: INFO
  metrics_endpoint: /metrics
  health_endpoint: /health
  performance_tracking: true
  
# Cache Configuration
cache:
  embedding_cache: true
  query_cache: true
  response_cache: true
  cache_backend: redis  # redis, memcached, in_memory
  redis_url: redis://localhost:6379
  ttl_seconds: 3600

# Error Handling
error_handling:
  max_retries: 3
  retry_delay: 1
  fallback_to_simple: true
  log_errors: true
  alert_on_failure: false

# A/B Testing
ab_testing:
  enabled: true
  experiments:
    - name: retrieval_strategy
      variants:
        - hybrid
        - dense_only
      traffic_split: [0.5, 0.5]
    - name: chunk_size
      variants:
        - 256
        - 512
      traffic_split: [0.3, 0.7]

# Rate Limiting
rate_limiting:
  enabled: true
  requests_per_minute: 60
  requests_per_hour: 1000
  burst_size: 10

# Security
security:
  input_validation: true
  max_input_length: 1000
  sanitize_outputs: true
  block_harmful_content: true
  audit_logging: true